{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BidirectionalTestAverageMode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanap5kr/DeepTest/blob/master/BidirectionalTestAverageMode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_cQdx_uMajP",
        "colab_type": "code",
        "outputId": "84cda871-479c-42f1-faa6-9ab56922b911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EBcSjUNKvrP",
        "colab_type": "text"
      },
      "source": [
        "###Bi-directional Test 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWpiN4IvK3SD",
        "colab_type": "code",
        "outputId": "a421be46-e3e4-4f63-f9cc-590cf3e4e2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from numpy import array\n",
        "import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "k_init = keras.initializers.Constant(value=0.1)\n",
        "b_init = keras.initializers.Constant(value=0.00)\n",
        "r_init = keras.initializers.Constant(value=0.1)\n",
        "# LSTM units\n",
        "units = 2\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(3, 2))\n",
        "# we should setting recurrent_activation = 'sigmoid' because default as 'hard_sigmoid'\n",
        "# lstm = LSTM(units, return_sequences = True, recurrent_activation='sigmoid', use_bias=False, activation='tanh',kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)(inputs1)\n",
        "bi = Bidirectional(LSTM(2, return_sequences=False, recurrent_activation='sigmoid', use_bias=False, activation='tanh', kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init), merge_mode='ave')(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=bi)\n",
        "for layer in model.layers:\n",
        "  g=layer.get_config()\n",
        "  h=layer.get_weights()\n",
        "  print (g)\n",
        "  print (h)\n",
        "# define input data\n",
        "data = array([0.1, 0.2, 0.3, 0.1, 0.2, 0.3]).reshape((1,3,2))\n",
        "# make and show prediction\n",
        "output = model.predict(data)\n",
        "print(output, output.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0801 07:02:45.710461 140285745248128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0801 07:02:45.711725 140285745248128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0801 07:02:45.714842 140285745248128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 3, 2), 'dtype': 'float32', 'sparse': False, 'name': 'input_2'}\n",
            "[]\n",
            "{'name': 'bidirectional_1', 'trainable': True, 'layer': {'class_name': 'LSTM', 'config': {'name': 'lstm_2', 'trainable': True, 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 2, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': False, 'kernel_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'recurrent_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'bias_initializer': {'class_name': 'Constant', 'config': {'value': 0.0}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, 'merge_mode': 'ave'}\n",
            "[array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)]\n",
            "[[0.01960772 0.01960772]] (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6lbL73tJt98",
        "colab_type": "text"
      },
      "source": [
        "###Bi-directional Test 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UTaxklNJxQt",
        "colab_type": "code",
        "outputId": "bec4d26b-98d8-4630-9789-36fecf33a06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from numpy import array\n",
        "import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "k_init = keras.initializers.Constant(value=0.1)\n",
        "b_init = keras.initializers.Constant(value=0.05)\n",
        "r_init = keras.initializers.Constant(value=0.1)\n",
        "# LSTM units\n",
        "units = 2\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(3, 2))\n",
        "# we should setting recurrent_activation = 'sigmoid' because default as 'hard_sigmoid'\n",
        "# lstm = LSTM(units, return_sequences = True, recurrent_activation='sigmoid', use_bias=False, activation='tanh',kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)(inputs1)\n",
        "bi = Bidirectional(LSTM(2, return_sequences= False, recurrent_activation='sigmoid', use_bias=False, activation='linear', kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init), merge_mode='ave')(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=bi)\n",
        "for layer in model.layers:\n",
        "  g=layer.get_config()\n",
        "  h=layer.get_weights()\n",
        "  print (g)\n",
        "  print (h)\n",
        "# define input data\n",
        "data = array([0.1, 0.2, 0.3, 0.1, 0.2, 0.3]).reshape((1,3,2))\n",
        "# make and show prediction\n",
        "output = model.predict(data)\n",
        "print(output, output.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 3, 2), 'dtype': 'float32', 'sparse': False, 'name': 'input_3'}\n",
            "[]\n",
            "{'name': 'bidirectional_2', 'trainable': True, 'layer': {'class_name': 'LSTM', 'config': {'name': 'lstm_3', 'trainable': True, 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 2, 'activation': 'linear', 'recurrent_activation': 'sigmoid', 'use_bias': False, 'kernel_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'recurrent_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'bias_initializer': {'class_name': 'Constant', 'config': {'value': 0.05}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, 'merge_mode': 'ave'}\n",
            "[array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)]\n",
            "[[0.01963189 0.01963189]] (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgNCmOnDIVbL",
        "colab_type": "text"
      },
      "source": [
        "### Bi-directional Test 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDX0ONUSZRET",
        "colab_type": "code",
        "outputId": "facd89dc-9029-4ddc-bfeb-e8abc3969c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from numpy import array\n",
        "import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "k_init = keras.initializers.Constant(value=0.1)\n",
        "b_init = keras.initializers.Constant(value=0.00)\n",
        "r_init = keras.initializers.Constant(value=0.2)\n",
        "# LSTM units\n",
        "units = 2\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(3, 2))\n",
        "# we should setting recurrent_activation = 'sigmoid' because default as 'hard_sigmoid'\n",
        "# lstm = LSTM(units, return_sequences = True, recurrent_activation='sigmoid', use_bias=False, activation='tanh',kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init)(inputs1)\n",
        "bi = Bidirectional(LSTM(2, return_sequences=True, recurrent_activation='sigmoid', use_bias=False, activation='tanh', kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init), merge_mode='ave')(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=bi)\n",
        "for layer in model.layers:\n",
        "  g=layer.get_config()\n",
        "  h=layer.get_weights()\n",
        "  print (g)\n",
        "  print (h)\n",
        "# define input data\n",
        "data = array([0.1, 0.2, 0.3, 0.1, 0.2, 0.3]).reshape((1,3,2))\n",
        "# make and show prediction\n",
        "output = model.predict(data)\n",
        "print(output, output.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 3, 2), 'dtype': 'float32', 'sparse': False, 'name': 'input_4'}\n",
            "[]\n",
            "{'name': 'bidirectional_3', 'trainable': True, 'layer': {'class_name': 'LSTM', 'config': {'name': 'lstm_4', 'trainable': True, 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 2, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': False, 'kernel_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'recurrent_initializer': {'class_name': 'Constant', 'config': {'value': 0.2}}, 'bias_initializer': {'class_name': 'Constant', 'config': {'value': 0.0}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, 'merge_mode': 'ave'}\n",
            "[array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
            "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
            "       [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]], dtype=float32)]\n",
            "[[[0.01340423 0.01340423]\n",
            "  [0.01685392 0.01685392]\n",
            "  [0.01788564 0.01788564]]] (1, 3, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT32bXDdfC54",
        "colab_type": "text"
      },
      "source": [
        "###Bonus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU0l2sRzN-j1",
        "colab_type": "code",
        "outputId": "40ceaebc-d072-475a-a6e7-bbbe9ca08822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for layer in model.layers:\n",
        "  g=layer.get_config()\n",
        "  h=layer.get_weights()\n",
        "  print (g)\n",
        "  print (h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_input_shape': (None, 3, 2), 'dtype': 'float32', 'sparse': False, 'name': 'input_25'}\n",
            "[]\n",
            "{'name': 'bidirectional_21', 'trainable': True, 'layer': {'class_name': 'LSTM', 'config': {'name': 'lstm_25', 'trainable': True, 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 2, 'activation': 'linear', 'recurrent_activation': 'sigmoid', 'use_bias': False, 'kernel_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'recurrent_initializer': {'class_name': 'Constant', 'config': {'value': 0.1}}, 'bias_initializer': {'class_name': 'Constant', 'config': {'value': 0.05}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}}, 'merge_mode': 'sum'}\n",
            "[array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32), array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
            "       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xozd3Ip2UbwV",
        "colab_type": "code",
        "outputId": "4bcfb100-c1eb-4a77-ea3a-969ae6804732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "\n",
        "# We create a layer which take as input movies of shape\n",
        "# (n_frames, width, height, channels) and returns a movie\n",
        "# of identical shape.\n",
        "\n",
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   input_shape=(None, 40, 40, 1),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n",
        "\n",
        "# Artificial data generation:\n",
        "# Generate movies with 3 to 7 moving squares inside.\n",
        "# The squares are of shape 1x1 or 2x2 pixels,\n",
        "# which move linearly over time.\n",
        "# For convenience we first create movies with bigger width and height (80x80)\n",
        "# and at the end we select a 40x40 window.\n",
        "\n",
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
        "                              dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 3 to 7 moving squares\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
        "                             y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the network to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,\n",
        "                                 x_shift - w - 1: x_shift + w + 1,\n",
        "                                 y_shift - w - 1: y_shift + w + 1,\n",
        "                                 0] += noise_f * 0.1\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
        "                               y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "# Train the network\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
        "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
        "        epochs=300, validation_split=0.05)\n",
        "\n",
        "# Testing the network on one movie\n",
        "# feed it with the first 7 positions and then\n",
        "# predict the new positions\n",
        "which = 1004\n",
        "track = noisy_movies[which][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions\n",
        "# to the ground truth\n",
        "track2 = noisy_movies[which][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig('%i_animate.png' % (i + 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 08:43:27.625468 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0731 08:43:27.666754 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0731 08:43:27.674414 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0731 08:43:27.979949 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0731 08:43:28.885545 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0731 08:43:28.903321 140458505295744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0731 08:43:28.909248 140458505295744 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 950 samples, validate on 50 samples\n",
            "Epoch 1/300\n",
            "950/950 [==============================] - 58s 61ms/step - loss: 0.2614 - val_loss: 0.0779\n",
            "Epoch 2/300\n",
            "580/950 [=================>............] - ETA: 18s - loss: 0.0278"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}